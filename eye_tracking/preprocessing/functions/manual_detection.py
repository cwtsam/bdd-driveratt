from pupil_apriltags import Detector, Detection
from collections import defaultdict
from typing import List, Dict, Tuple, Any
from glob import glob
import os
import time
import sys
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import numpy as np
import cv2
import pandas as pd


def extract_frames(video_path: str, frames_path: str) -> None:
    """Convert a video (mp4 or similar) into a series of individual PNG frames.
    Make sure to create a directory to store the frames before running this function.
    Args:
        video_path (str): filepath to the video being converted
        frames_path (str): filepath to the target directory that will contain the extract frames
    """
    video = cv2.VideoCapture(video_path)
    count = 0
    success = 1

    # Basically just using OpenCV's tools
    while success:
        success, frame = video.read()
        cv2.imwrite(f'{frames_path}/frame{count}.png', frame)
        count += 1

    # Optional print statement
    print(f'Extracted {count} frames from {video_path}.')


def detect_tags(frames_path: str, tags = [0, 1, 2, 3, 5, 6, 7, 8, 9, 11], aperture=11, visualize=False) -> Tuple[List[List[Dict[str, Any]]], Dict[int, int]]:
    """Detect all tags (Apriltags3) found in a folder of PNG files and return (1) a list of tag objects
    for preprocessing and (2) a dictionary containing the frequency that each tag ID appeared
    Args:
        frames_path (str): path to the directory containing PNG images
        tags (int):
        aperture (int):
        visualize (bool):

    Returns:
        frames (List[Dict[str, Any]]): list of objects containing id (int), centroid (np.array[int]) and corners (np.array[int])
        tag_ds (Dict[int, int]): dictionary mapping tag IDs to frequency of tag across all images
    """
    # Initialize variables
    frames = []
    tag_ids = defaultdict(int)
    at_detector = Detector()

    # Sort by index in.../frame<index>.png
    all_images = sorted(glob(f'{frames_path}/*.png'), key=lambda f: int(os.path.basename(f)[5:-4]))

    # Deleted last image after out of range error popped up
    # TODO: but not analyzing last 2 frames?
    # print(len(all_images))
    if len(all_images) > 1:
        all_images = all_images[:-1]

    num_images = len(all_images)
    # print_progress_bar(0, num_images, prefix='Progress:', suffix='Complete', length=50)

    starting_frame = False
    # Iterate thru all PNG images in frames_path
    for i, img_path in enumerate(all_images):
        # Create a grayscale 2D NumPy array for Detector.detect()
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        if type(img) == np.ndarray:
            tags_in_framex = []
            for tag in at_detector.detect(img):
                # Increment frequency
                tag_ids[tag.tag_id] += 1
                # r = np.roll(np.float32(img), tag.homography + 1, axis=0)
                # Add to frames in following format - feel free to adjust
                tags_in_framex.append({
                    'id': tag.tag_id,
                    'id_confidence': tag.decision_margin,
                    'soft_id': tag.tag_id,
                    'perimeter': 100, #cv2.arcLength(img, closed=True),
                    'centroid': tag.center,
                    'verts': tag.corners,
                    'frames_since_true_detection': 0
                })

                # {'id': msg, 'id_confidence': id_confidence, 'verts': r.tolist(), 'soft_id': soft_msg,
                #  'perimeter': cv2.arcLength(r, closed=True), 'centroid': centroid.tolist(),
                #  "frames_since_true_detection": 0}
            frames.append(tags_in_framex)

        if len(tags_in_framex) == 10:
            starting_frame = True

        # img_n = int(''.join(list(filter(str.isdigit, img_path))))
        # if img_n >= starting_frame_n:
        if starting_frame:
            # create bounding box
            bounding_box(frames_path, frames, img_path, tags)

        time.sleep(0.01)
        print_progress_bar(i + 1, num_images, prefix='Progress:', suffix='Complete', length=50)

    return frames, dict(tag_ids)

#function that gets what attribute is of the dictionary generated by detect tags a user needs
#for instance, I needed the centers of each tag and the corners to crop the image, so this function acquires tgem from the
#return call of detect tags
def attribute(frame, feature):
    qr_codes = frame
    attributes = []
    for i in range(len(qr_codes)):
        qr_code = qr_codes[i]
        attributes.append(qr_code[feature])
    return attributes

def bb_coordinates(frame, tag):
    for f in frame:
        id = attribute(f, 'id')

        # extrapolate coordinates from prev coordinates if it doesn't exist
        while len(id) < len(tag):
            id.append('None')

        # attains the corners for each of the QR codes in the frame; not sorted in any order
        corners = attribute(f, 'verts')
        # bottom left corners[x][0]
        # bottom right corners[x][1]
        # top right corners[x][2]
        # top left corners[x][3]

        centers = attribute(f, 'centroid')

        # coordinates to create the rectangle
        if tag[0] in id:
            i = id.index(tag[0])
            top_left = corners[i][3]
        if tag[5] in id:
            i = id.index(tag[5])
            bottom_right = corners[i][1]

        # coordinates to create the horizontal line
        if tag[1] in id:
            i = id.index(tag[1])
            left = centers[i]
        if tag[6] in id:
            i = id.index(tag[6])
            right = centers[i]

        # coordinates to create the vertical line
        if tag[3] in id:
            i = id.index(tag[3])
            bottom_center_left = centers[i]
        if tag[4] in id:
            i = id.index(tag[4])
            bottom_center_right = centers[i]
        if tag[8] in id:
            i = id.index(tag[8])
            top_center_right = centers[i]
        if tag[9] in id:
            i = id.index(tag[9])
            top_center_left = centers[i]

        # # other tags
        # if tag[2] in id:
        #     i = id.index(tag[2])
        #     bottom_left = corners[i][0]
        # if tag[7] in id:
        #     i = id.index(tag[7])
        #     top_right = corners[i][2]

        # coordinates = [top_left, left, bottom_left, bottom_center_left, bottom_center_right,
        #                 bottom_right, right, top_right, top_center_right, top_center_left]

    return top_left, left, bottom_center_left, bottom_center_right, bottom_right, right, top_center_right, top_center_left


def bounding_box(folder, frame, img_path, tag):
    # Create frame path using OS package
    # Define the name of the directory to be created
    bounding_box_frames_path = folder + "/bounding_box_frames"
    try:
        if not os.path.exists(bounding_box_frames_path):
            os.mkdir(bounding_box_frames_path)
            print("Successfully created the directory %s " % bounding_box_frames_path)
        else:
            print("Directory %s already exists." % bounding_box_frames_path)
    except OSError:
        print("Creation of the directory %s failed" % bounding_box_frames_path)

    top_left, left, bottom_center_left, bottom_center_right, bottom_right, right, top_center_right, top_center_left = bb_coordinates(frame, tag)

    img = cv2.imread(img_path, cv2.IMREAD_COLOR)
    # pts = np.array(coordinates, np.int32)
        # pts = np.array([top_left, bottom_left, bottom_right, top_right], np.int32)

    # polygon correctly fitted to the surface
    # pts = pts.reshape((-1, 1, 2))
    # cv2.polylines(img, [pts], True, (0, 255, 255), 3)

    red = (0, 0, 255)
    thickness = 2

    tl = tuple(top_left.astype(int))
    br = tuple(bottom_right.astype(int))
    cv2.rectangle(img, tl, br, red, thickness)

    l = tuple(left.astype(int))
    r = tuple(right.astype(int))
    cv2.line(img, l, r, red, thickness)

    bottom_midpoint = (((bottom_center_right[0] + bottom_center_left[0])/2).astype(int),
                       ((bottom_center_right[1] + bottom_center_left[1])/2).astype(int))
    top_midpoint = (((top_center_right[0] + top_center_left[0]) / 2).astype(int),
                    ((top_center_right[1] + top_center_left[1]) / 2).astype(int))
    cv2.line(img, bottom_midpoint, top_midpoint, red, thickness)

    head, tail = os.path.split(img_path)
    cv2.imwrite(bounding_box_frames_path + "/" + tail, img)


def print_progress_bar (iteration, total, prefix ='', suffix ='', decimals = 1, length = 100, fill ='â–ˆ', printEnd ="\r"):
    """
    Call in a loop to create terminal progress bar
    @params:
        iteration   - Required  : current iteration (Int)
        total       - Required  : total iterations (Int)
        prefix      - Optional  : prefix string (Str)
        suffix      - Optional  : suffix string (Str)
        decimals    - Optional  : positive number of decimals in percent complete (Int)
        length      - Optional  : character length of bar (Int)
        fill        - Optional  : bar fill character (Str)
        printEnd    - Optional  : end character (e.g. "\r", "\r\n") (Str)
    """
    percent = ("{0:." + str(decimals) + "f}").format(100 * (iteration / float(total)))
    filledLength = int(length * iteration // total)
    bar = fill * filledLength + '-' * (length - filledLength)
    sys.stdout.write('\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix))
    # Print New Line on Complete
    if iteration == total:
        print()